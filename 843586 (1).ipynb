{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c241b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_table('Part 1.tsv', comment='#')\n",
    "\n",
    "pt1 = df.sample(frac=0.2)\n",
    "\n",
    "X1 = pt1.iloc[:, :6].values\n",
    "y1 = pt1[\"target\"].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de1df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c08225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from rich.progress import track\n",
    "\n",
    "# implement the activation and cost functions\n",
    "def sigmoid(Z):\n",
    "    return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "def sigmoid_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "def cost_function(y1, y1_hat):\n",
    "  \n",
    "    # sum of squares error function\n",
    "    return np.sum(np.square(y1 - y1_hat))*0.5\n",
    "\n",
    "def cost_gradient(y1, y1_hat):\n",
    "\n",
    "  # derivative of the cost function\n",
    "    return -(y1 - y1_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaedddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From lab 09\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "def print_dim(name, var):\n",
    "    print(f\"{name} = {var.shape}\")\n",
    "\n",
    "class FiveLayerPerceptronRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    A fully connected 5-layer perceptron for binary regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    size_hidden : int\n",
    "        The size of the hidden layer\n",
    "    epochs : int\n",
    "        The number of epochs to train the model\n",
    "    leargning_rate : float\n",
    "        The learning rate for the gradient descent\n",
    "    batch_size : int, default 50\n",
    "        The number of datapoints in each mini-batch\n",
    "    random_state : random_state, default None\n",
    "        a numpy random state for reproducibility. If None (default)\n",
    "        The default numpy random generator with seed 0 will be used\n",
    "\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This implementation initializes the weights using a random Gaussian\n",
    "    distribution with mean 0 and standard deviation 0.001\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 size_hidden, \n",
    "                 epochs, \n",
    "                 learning_rate, \n",
    "                 batch_size, \n",
    "                 random_state=None):\n",
    "        self.size_hidden = size_hidden\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        if random_state is None:\n",
    "            self.rng = np.random.default_rng(0)\n",
    "        else:\n",
    "            self.rng = random_state\n",
    "        # the dimensionality of _W0 will be set in the fit function\n",
    "        self._W1 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W2 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W3 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W4 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W5 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, 1))\n",
    "        self.training_losses = np.zeros(self.epochs)\n",
    "        \n",
    "    def _forward(self, X1):\n",
    "        # 1st layer\n",
    "        self.O1 = X1 @ self._W0\n",
    "        self.A1 = sigmoid(self.O1)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A1.shape\n",
    "        self.A1 = np.c_[np.ones((n, 1)), self.A1]\n",
    "\n",
    "        # 2nd layer \n",
    "        self.Z2 = self.A1 @ self._W1\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A2.shape\n",
    "        self.A2 = np.c_[np.ones((n, 1)), self.A2]\n",
    "\n",
    "        # 3rd layer \n",
    "        self.Z3 = self.A2 @ self._W2\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A3.shape\n",
    "        self.A3 = np.c_[np.ones((n, 1)), self.A3]\n",
    "\n",
    "        # 4th layer \n",
    "        self.Z4 = self.A3 @ self._W3\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A4.shape\n",
    "        self.A4 = np.c_[np.ones((n, 1)), self.A4]\n",
    "\n",
    "        # 5th layer\n",
    "        self.O5 = self.A4 @ self._W4\n",
    "        self.A5 = sigmoid(self.O5)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A5.shape\n",
    "        self.A5 = np.c_[np.ones((n, 1)), self.A5]\n",
    "\n",
    "        # 6th layer or output layer\n",
    "        self.O6 = self.A5 @ self._W5\n",
    "        self.A6 = self.O6\n",
    "\n",
    "        # return the identity of the output layer instead of the sigmoid\n",
    "        return self.A6\n",
    "        \n",
    "    def _backward(self, X1, y1):\n",
    "\n",
    "        # starting by the last one\n",
    "        dA6 = cost_gradient(y1, self.A6)\n",
    "        dO6 = dA6 * sigmoid_derivative(sigmoid(self.O6))\n",
    "        dW5 = self.A5.T @ dO6\n",
    "\n",
    "        # 5th layer backpropagation\n",
    "        dA5 = dO6 @ self._W5[1:,:].T\n",
    "        dO5 = dA5 * sigmoid_derivative(sigmoid(self.O5))\n",
    "        dW4 = self.A4.T @ dO5\n",
    "\n",
    "        # 4th layer backpropagation\n",
    "        dA4 = dO5 @ self._W4[1:,:].T\n",
    "        dO4 = dA4 * sigmoid_derivative(sigmoid(self.Z4))\n",
    "        dW3 = self.A3.T @ dO4\n",
    "\n",
    "        # 3rd layer backpropagation\n",
    "        dA3 = dO4 @ self._W3[1:,:].T\n",
    "        dO3 = dA3 * sigmoid_derivative(sigmoid(self.Z3))\n",
    "        dW2 = self.A2.T @ dO3\n",
    "\n",
    "        # 2nd layer backpropagation\n",
    "        dA2 = dO3 @ self._W2[1:,:].T\n",
    "        dO2 = dA2 * sigmoid_derivative(sigmoid(self.Z2))\n",
    "        dW1 = self.A1.T @ dO2\n",
    "\n",
    "        # 1st layer backpropagation\n",
    "        dA1 = dO2 @ self._W1[1:,:].T\n",
    "        dO1 = dA1 * sigmoid_derivative(sigmoid(self.O1))\n",
    "        dW0 = X1.T @ dO1\n",
    "\n",
    "        return dW0, dW1, dW2, dW3, dW4, dW5\n",
    "\n",
    "        \n",
    "    def _weight_update(self, dW0, dW1, dW2, dW3, dW4, dW5, curr_batch_size):\n",
    "        self._W0 -= self.learning_rate * dW0\n",
    "        self._W1 -= self.learning_rate * dW1\n",
    "        self._W2 -= self.learning_rate * dW2\n",
    "        self._W3 -= self.learning_rate * dW3\n",
    "        self._W4 -= self.learning_rate * dW4\n",
    "        self._W5 -= self.learning_rate * dW5\n",
    "\n",
    "\n",
    "    def fit(self, X1, y1):\n",
    "        X1, y1 = check_X_y(X1, y1)\n",
    "        n, m = X1.shape\n",
    "        _X1 = np.c_[np.ones((n, 1)), X1]\n",
    "        _y1 = y1[:,np.newaxis]\n",
    "        self._W0 = self.rng.normal(scale=0.001, size=(m+1, self.size_hidden))\n",
    "        \n",
    "        #number of batches\n",
    "        n_batches = (n + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for epoch in track(range(self.epochs), description=\"Training...\"):\n",
    "            for b in range(n_batches):\n",
    "                _X1_batch = _X1[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                _y1_batch = _y1[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                y_pred = self._forward(_X1_batch)\n",
    "                dW0, dW1, dW2, dW3, dW4, dW5  = self._backward(_X1_batch, _y1_batch)\n",
    "                curr_batch_size = _y1_batch.shape[0]\n",
    "                self._weight_update(dW0, dW1, dW2, dW3, dW4, dW5, curr_batch_size)\n",
    "            y1_pred = self._forward(_X1)\n",
    "            self.training_losses[epoch] = cost_function(_y1, y1_pred)\n",
    "        \n",
    "        self.fitted_ = True\n",
    "    \n",
    "    def predict(self, X1):\n",
    "        return self.predict_proba(X1).argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X1):\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        X1 = check_array(X1)\n",
    "        n, m = X1.shape\n",
    "        _X1 = np.c_[np.ones((n, 1)), X1]\n",
    "        \n",
    "        pred_1 = self._forward(_X1)\n",
    "        pred_0 = 1 - pred_1\n",
    "        return np.c_[pred_0, pred_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d22371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training... <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 70%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training... \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[35m 70%\u001b[0m \u001b[36m0:00:38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implementation from lab 09\n",
    "\n",
    "model = FiveLayerPerceptronRegressor(3, 1000, 0.001, 5)\n",
    "model.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f499f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAJJCAYAAAB/B+mYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABCpElEQVR4nO3deZycV33n+8+vqjeptXVrs1ZLXvACeEPesGFsk9jGgA0JiwmLIYBvJpBwkzthIMkrzCWXmTDJJIQMIUOICbtZjR0wNgZjMAleJNt4X4Rs2RKSJVuydvVSde4f9VR3qd2yWlI/Xd39fN6vV7+q6tRTVaeqKPnLOb/nnEgpIUmSpPyUmt0BSZKkyc7AJUmSlDMDlyRJUs4MXJIkSTkzcEmSJOXMwCVJkpSzCR24IuJNEfFARFQjYsUBji1HxN0R8b2Gtn+JiF9GxL0R8a2ImJa1vysiNkfEPdnfexsec0VEPJb9XdHQ/rKIuC8iVkfEpyIisvbuiLgpO/6miOjK2iM7bnX2+qeN9mu8wGfxtob3dk/2+Z0ywo9dkiQdpAkTuCLivIj41yHN9wO/BfxsBE/xQeChIW1/lFI6OaV0EvAk8IGG+76eUjol+/tc1odu4KPAmcAZwEcbws1ngPcBx2Z/F2ftHwZ+nFI6Fvhxdhvg1Q3HXpk9frRfY1gppa/U3xvwDuDxlNI9L/QYSZJ06CZM4BpOSumhlNIjBzouIhYDrwE+N+Tx27P7A5gCHGgV2IuAm1JKW1JKW4GbgIsjYgEwI6V0W6qtJPtF4PXZYy4DvpBd/8KQ9i+mmtuAWdnzjNprRERnRFwVEXdko3uXDfOe3gpcfYD3LUmSDsOEDlwH4ZPAh4Dq0Dsi4vPARuB44B8a7vrthqnGJVnbIuCphmPWZW2LsutD2wHmp5Q2ZNc3AvNH8Fyj9Rp/BtycUjoDOB/464joHPIRvAX4GpIkKTfjPnBFxO0RcQ+10alLG+qOLhrh418LbEoprRru/pTSu4GF1KYb35I1/xuwLJtqvInB0aPDko1M5bqX0pDXuBD4cPb53QJ0AEvrx0bEmcDulNL9efZJkqSiG/eBK6V0ZlZr9F7guoa6qhtH+BTnUAtqT1CbOrsgIr485DUq2X2/nd1+NqXUk939OeBl2fX1wJKGhy7O2tZn14e2AzydTQeSXW4awXON1msE8NsNn9nSlFJjHdvlOLolSVLuxn3gOlwppY+klBanlJZRCxg3p5Tenp0leAwM1HBdCjyc3V7Q8BSXMlhsfyNwYUR0ZYXsFwI3ZtN52yPirOy53glcmz3mOqB+puEVQ9rfmfXjLGBb9jyj+Ro3An/QcDbjqfU3FREl4M1YvyVJUu5amt2BwxERb6BWdzUX+H5E3JNSuigiFgKfSyld8kIPB74QETOy678E/nN23x9GxKVAP7AFeBdASmlLRPwlcGd23MdSSluy678P/Cu14vsfZH8AfwV8IyLeA6ylFnIArgcuAVYDu4F35/Aaf0mtfu3eLGA9Drw2u++VwFMppTUv8BlJkqRRELWSH0mSJOVl0k8pSpIkNdu4nlKcM2dOWrZsWbO7IUmSdECrVq16JqU0d7j7xnXgWrZsGStXrmx2NyRJkg4oItbu7z6nFCVJknJm4JIkScqZgUuSJClnBi5JkqScGbgkSZJyZuCSJEnKmYFLkiQpZwYuSZKknBm4JEmScmbgkiRJypmBS5IkKWcGLkmSpJwZuCRJknJm4JIkScqZgUuSJClnBi5JkqScGbgkSZJyZuCSJEnKmYFLkiQpZyMKXBHxRETcFxH3RMTKrO2vI+LhiLg3Iq6JiFkNx38kIlZHxCMRcVFD+8VZ2+qI+PCovxtJkqRx6GBGuM5PKZ2SUlqR3b4JeElK6STgUeAjABFxInA58GLgYuAfI6IcEWXg08CrgROBt2bHSpIkTWqHPKWYUvphSqk/u3kbsDi7fhlwdUqpJ6X0OLAaOCP7W51SWpNS6gWuzo6VJEma1EYauBLww4hYFRFXDnP/7wI/yK4vAp5quG9d1ra/9n1ExJURsTIiVm7evHmE3cvPzp5+/vgb9/DHX7+HHXv7mt0dSZI0AbWM8LhzU0rrI2IecFNEPJxS+hlARPwZ0A98ZTQ6lFL6LPBZgBUrVqTReM7D8c8/W8N37loPQHtrif/xWyc1uUeSJGmiGdEIV0ppfXa5CbiG2vQgEfEu4LXA21JK9XC0HljS8PDFWdv+2setlBLfWrWO84+by7tevoxvrFzH+uf2NLtbkiRpgjlg4IqIzoiYXr8OXAjcHxEXAx8CLk0p7W54yHXA5RHRHhHLgWOBO4A7gWMjYnlEtFErrL9udN/O6Fq3dQ/rn9vDecfN4z3nLqdSTXz37nGdESVJ0jg0kinF+cA1EVE//qsppRsiYjXQTm2KEeC2lNLvpZQeiIhvAA9Sm2p8f0qpAhARHwBuBMrAVSmlB0b9HY2iu57cCsDpy7pZ0j2VFUd2cd09v+b95x/T5J5JkqSJ5ICBK6W0Bjh5mPb9po6U0seBjw/Tfj1w/UH2sWl+tWknpYCj53UCcOkpC/mLax/g0ad38KL505vcO0mSNFG40vwL+NXmXSztnkp7SxmAC088AoBbHtnUzG5JkqQJxsD1AtY8s4vlczoHbh8xs4MXzZ/GrY8908ReSZKkicbA9QI2bNvDoq4p+7S94ti53P74Fvb2VZrUK0mSNNEYuPZjb1+F53b3sWDm0MA1h97+Knc8vqVJPZMkSRONgWs/nt6+F4D5Mzr2aT9z+WzayiVufaz5q+BLkqSJwcC1Hxu21QLXEUMC15S2MiuWdfHz1c82o1uSJGkCMnDtx6YdPQDMn9H+vPvOWN7Nwxu3s22PeytKkqQDM3Dtx9ZdvQB0dbY9774zlnWTEty1dutYd0uSJE1ABq792Lq7FrhmTWl93n2nLu2ipRTc8YSF85Ik6cAMXPvx3O4+pne00FJ+/kc0pa3MSxbN5E7PVJQkSSNg4NqPrbt76Zr6/OnEujOWd3Pvum2uxyVJkg7IwLUfW3f30TX1+dOJdacv66a3UuWXTz03dp2SJEkTkoFrP57b3cusFxjhWnFkFwB3WsclSZIOwMC1H9v29DHrBUa4ujrbeNH8adzxhGcqSpKkF2bg2o+de/uZ3tHygsecvqybu9ZupVJNY9QrSZI0ERm49mNHTz+d7S8cuM5Y3s3Onn4e2rB9jHolSZImIgPXMHr6K/T2V5l+gMB1+rJuwDouSZL0wgxcw9jVU1vqYdoBAtfCWVNYNGsKK63jkiRJL8DANYyde/sBmNax/6L5uhXLurjziS2kZB2XJEkanoFrGDt6aptSH2iEC2DFsm427ejhqS178u6WJEmaoAxcw6iPcB3oLEWA05fV1uNaudY6LkmSNDwD1zB29mRTiiMY4XrRvOlM72jhTuu4JEnSfhi4hlEPXAdaFgKgVApedmQXKz1TUZIk7YeBaxi7e2tnKXa2l0d0/OnLunls00627urNs1uSJGmCMnANY08WuKa0jixw1fdVXLXWaUVJkvR8Bq5h7OmrBa6OEQauk5fMorUc3GnhvCRJGoaBaxh7+ypEQHvLyD6ejtYyL1k0k1UWzkuSpGEYuIaxu7fC1NYyETHix5y+rJt7121jbzY6JkmSVGfgGsaevgpT2kY2nVi34sgueitV7lu/LadeSZKkicrANYy9vZUR12/VvSwrnHcja0mSNJSBaxh7+ipMPcgRrtnT2jl6bqcbWUuSpOcxcA1jd29lxEtCNFpxZDer1m6lWnUja0mSNMjANYw9fQc/pQiwYlkX2/b0sXrzzhx6JUmSJioD1zD2HkLRPNTOVATruCRJ0r4MXMPY3XvwNVwAR86eypxp7dZxSZKkfRi4hrG3r0JHy8EHrojg9GVdjnBJkqR9GLiG0dNfpb310D6alx3Zxbqte9i4be8o90qSJE1UBq5h9PZXaT+EES4YrONa6b6KkiQpY+AaRk9/hbYR7qM41IkLZzCltWwdlyRJGmDgGiKlVJtSPMTA1VoucerSWdZxSZKkAQauIfoqiZQ45MAFsGJZNw9t2M6OvX2j2DNJkjRRGbiG6K1UAQ65hgtqG1lXE9z95HOj1CtJkjSRGbiG6OmrABxyDRfAqUtnUQpYudY6LkmSZOB6np7++gjXoX800ztaOWHBDFZaxyVJkjBwPU9vPXAd4jpcdacv6+auJ7cOPJ8kSSouA9cQ9RGutvKh13ABnHVUN3v7qty77rlR6JUkSZrIDFxD9PTXargOZ0oR4IzlswG4bc2zh90nSZI0sRm4hhitKcXuzjaOP2I6t62xjkuSpKIzcA0xOKV4+B/NWUfNZuXaLQOjZpIkqZgMXEMMTCm2Hl4NF9QCV62Oa9thP5ckSZq4DFxD9PQd/rIQdWcur21kfduvrOOSJKnIDFxDDK40f/gfTVe9jutxA5ckSUVm4BqiXsPVOgo1XABnHz2bVWu3WsclSVKBGbiG6MtGuA5na59G9TquXz5lHZckSUVl4Bqib5RHuM5c3k2E63FJklRkBq4h+qsJgNZyjMrzzZraxvFHzDBwSZJUYAauIepF86M1wgVw9lHWcUmSVGQGriH6+usjXKP30Zx1VDc9/dZxSZJUVAauIfoqVUoB5dLoTCkCnLl8NhHwH796ZtSeU5IkTRwGriH6KtVRHd0CmDm1lZcumsnPHzNwSZJURAauIfoqaVT2URzq3GPmcPdTz7Fjb9+oP7ckSRrfDFxD9FWqtI7SGlyNzj1mDpVq4vY1W0b9uSVJ0vhm4BqiNqU4evVbdS9b1kVHa4mfr3ZaUZKkojFwDdFbqdJSGv2Ppb2lzBnLZ3PrY5tH/bklSdL4ZuAaoq+SRm1bn6FeccwcfrV5Fxu27cnl+SVJ0vhk4BqiP6cpRYBzj50D4NmKkiQVjIFriDyWhag7bv505kxrs45LkqSCMXAN0VtJuQWuUik455g5/PvqZ6hmezZKkqTJz8A1RF9/NZd1uOrOPWYOz+zs5ZGnd+T2GpIkaXwxcA3RV6nSklMNF1jHJUlSERm4huir5jelCLBg5hSOntvJrdZxSZJUGAauIfr68yuar3vFsXO54/Fn2dtXyfV1JEnS+GDgGqKvUqWtJb8pRYD/9KK57O2rcsfjbvMjSVIRjChwRcQTEXFfRNwTESuztjdFxAMRUY2IFUOO/0hErI6IRyLioob2i7O21RHx4dF9K6Mjz2Uh6s4+ejbtLSV+8simXF9HkiSNDweTLM5PKZ2SUqqHq/uB3wJ+1nhQRJwIXA68GLgY+MeIKEdEGfg08GrgROCt2bHjSl8l5bK1T6OO1jIvP3o2P3nYwCVJUhEccrJIKT2UUnpkmLsuA65OKfWklB4HVgNnZH+rU0prUkq9wNXZseNKfzW/leYbnX/8PJ54djePP7Mr99eSJEnNNdLAlYAfRsSqiLjyAMcuAp5quL0ua9tf+z4i4sqIWBkRKzdvHvuNnvsriXIp/8B13ovmATjKJUlSAYw0cJ2bUjqN2nTg+yPilXl1KKX02ZTSipTSirlz5+b1MvvVX020jEHgWjp7KkfP7bSOS5KkAhhR4Eoprc8uNwHXUJse3J/1wJKG24uztv21jyuVaqIl56L5uvOPm8fta7awu7d/TF5PkiQ1xwGTRUR0RsT0+nXgQmoF8/tzHXB5RLRHxHLgWOAO4E7g2IhYHhFt1ArrrzvcNzDa+irVMRnhglodV2+lyn+sfnZMXk+SJDXHSIZy5gM/j4hfUgtO308p3RARb4iIdcDZwPcj4kaAlNIDwDeAB4EbgPenlCoppX7gA8CNwEPAN7Jjx5XaCNfYBK4Vy7robCs7rShJ0iTXcqADUkprgJOHab+G2vTicI/5OPDxYdqvB64/+G6OjZQS/dVEOedlIeraW8qcc8wcbnlkMyklIsYm6EmSpLHlSvMNKtUEMGZTigAXHD+P9c/t4bFNO8fsNSVJ0tgycDXorweuMZpSBDjvuNryEDe7PIQkSZOWgatBfxNGuI6Y2cGJC2bwowefHrPXlCRJY8vA1aBSqQeusf1YLnzxfFY9uZXNO3rG9HUlSdLYMHA16KtWgbGdUgS48MQjSAlufthRLkmSJiMDV4N60fxYbO3T6IQF01ncNYUfPmDgkiRpMjJwNajXcLWO8ZRiRHDhiUdw6+pn2NXjqvOSJE02Bq4G/ZXalOJYj3AB/OaJ8+ntr/KzR8d+w25JkpQvA1eDZiwLUXf6si5mTW3lJs9WlCRp0jFwNehv0lmKAC3lEq86fj4/fngTfdlImyRJmhwMXA36q82bUoTa8hDb9vRx5+NbmvL6kiQpHwauBvWzFFubMKUI8Mpj59LeUuLGBzY25fUlSVI+DFwN+irNWRaibkpbmfOOm8sP7t9INQt/kiRp4jNwNRgc4Wrex/KakxayaUcPK9dubVofJEnS6DJwNWh2DRfAq46fR3tLievv29C0PkiSpNFl4GoweJZi8wJXZ3sL5x83j+vv2zAw4iZJkiY2A1eDysA6XM39WF5z0oLatOITnq0oSdJkYOBqUF//qpkjXAAXZNOK33daUZKkScHA1aDSxJXmG3W2t3DB8fP4wf0bnVaUJGkSMHA1GNjap8kjXFCbVty8o4c7nVaUJGnCM3A1GDxLsfkfywXHz6OjtcT37v11s7siSZIOU/OTxTgyHs5SrJva1sJvnDCf79+7wb0VJUma4AxcDer1Us1ch6vRG05dxNbdffz0kc3N7ookSToMBq4G46mGC+CVL5pLd2cb19yzvtldkSRJh8HA1aCaaoGrNE4CV2u5xOtOWsCPHnya7Xv7mt0dSZJ0iAxcDSrjbIQL4PWnLqKnv8oN929sdlckSdIhMnA1qAeu8TLCBXDKklksn9PJNXc5rShJ0kRl4GowUDQf4ydwRQSvP2URtz3+LL9+bk+zuyNJkg6BgatBJY2vsxTrXn/qQlKC637pmlySJE1EBq4Glcr4DFxHzu7kZUd28a1V60jJrX4kSZpoDFwNBka4xtGUYt1bVixh9aad3PXk1mZ3RZIkHSQDV4NqNRExvorm615z0gI628p8/c6nmt0VSZJ0kAxcDfqraVyObgF0trfwupMX8m+/3MAO1+SSJGlCMXA1qKQ0Lke36t5y+hL29FX43r0bmt0VSZJ0EAofuP779Q9x/X21AFOtpnG16OlQpyyZxXHzp3O104qSJE0ohQ9cX7vjSe58YgswvqcUobYm15tPX8Ivn3qOhzdub3Z3JEnSCBU+cDWqVsf3lCLAG05dRFu5xNV3OMolSdJEYeAC6ktbVdL4nlIE6O5s46KXHMF37lrH7t7+ZndHkiSNQOEDV2O8qkyAES6Ad559JNv39nPtPa48L0nSRFD4wNWoMs5ruOpWHNnFCQtm8MVfrHXleUmSJgADV4NKdfxt6zOciOCdZx/JQxu2s3KtK89LkjTeFT5wRcOIVqVanRCBC+CyUxYyo6OFL/zHE83uiiRJOoDCB65GlTQxRrgApra18OYVS7jh/o1s2r632d2RJEkvwMAFA3VQ1WqaMIEL4O1nHUklJb56x5PN7ookSXoBhQ9cjTXy/dXqhCiar1s2p5PzXjSXL9/2JHv7Ks3ujiRJ2o/CBy6A+nl+lSoTYlmIRu99xVE8s7OHa+9Z3+yuSJKk/Sh84GqMV9UJsPDpUC8/ejYvXjiDz/5sDdWqS0RIkjQeFT5wNeqfIAufNooIrnzlUfxq8y5ufnhTs7sjSZKGYeBicGufajVRnlh5C4BLXrqARbOm8NmfrWl2VyRJ0jAKH7j2XYcr0VKaeB9Ja7nE7567nDue2MLdT7oQqiRJ483ESxc5qu2l2OxeHJq3nL6EGR0tjnJJkjQOTdB4MbpSdp5iJU2sdbgaTWtv4R1nH8kND2zksad3NLs7kiSpQeEDV2O8qlQT5Yk6xAW859yjmNJa5h9uXt3srkiSpAYTN13koDJBi+brujvbeOfZy/i3e3/N6k07m90dSZKUMXAxeJZiZYJt7TOc971iOR0tZT79E0e5JEkaLwofuBp38pkMgWv2tHbecfaRXHvPeh5/ZlezuyNJkjBw7WMiF803et8rjqKtpcT/tpZLkqRxwcDF4F6K1WqiNIE2r96fudPbefuZR3LN3etYvckzFiVJajYDV8N5iv3VibeX4v78/vnHMLWthb++8ZFmd0WSpMIzcDWoTMC9FPenu7ONK195FDc+8DSr1rr6vCRJzWTgomEvxZQoT4Ipxbr3nLucOdPa+cQND5Pqb1KSJI25wgeuyXaWYqPO9hY++KpjuOPxLdzyyOZmd0eSpMIqfOBqVE2TZ0qx7vIzlnLk7Kl84oaHqVQd5ZIkqRkMXED9PMVqYlJNKQK0lkv814uP5+GNO/jaHU82uzuSJBVS4QPX0L0UJ9kAFwCvfskRnLm8m//1w0fYtruv2d2RJKlwCh+4YN+i+ck2pQgQEfy3S1/Mtj19/N2PHm12dyRJKpzCB67GGcTJsvDpcE5YMIPfOXMpX7ptLY9sdDFUSZLGUuEDV6NqYlKdpTjUH//mcXS2lfnY9x5wmQhJksaQgYvBKcVKSkzSAS6gthjqf7noOP599bNc98tfN7s7kiQVRuEDVzSUzadJtvDpcN525pGcvGQWH/u3B9m6q7fZ3ZEkqRAKH7gaVSZxDVdduRT81W+9lG17+vjv1z/U7O5IklQIBi4gkUgpUU1MyrMUhzphwQze+4qj+OaqdfzHr55pdnckSZr0Ch+46gNa9TquAuQtAD74qmNZ2j2VP7vmfvb2VZrdHUmSJrXCB666Spa4JnsNV92UtjL/47deyuPP7OITNzzc7O5IkjSpjShwRcQTEXFfRNwTESuztu6IuCkiHssuu7L2iIhPRcTqiLg3Ik5reJ4rsuMfi4gr8nlLBy+l2qKnUIwpxbpzjpnDFWcfyef//QmnFiVJytHBjHCdn1I6JaW0Irv9YeDHKaVjgR9ntwFeDRyb/V0JfAZqAQ34KHAmcAbw0XpIa6Z6vKpWa5eTvWh+qA+/+gSWz+nkT755Lzv2uu2PJEl5OJwpxcuAL2TXvwC8vqH9i6nmNmBWRCwALgJuSiltSSltBW4CLj6M1x9V9RGucsEmWae0lflfbz6ZDdv28LF/e7DZ3ZEkaVIaabxIwA8jYlVEXJm1zU8pbciubwTmZ9cXAU81PHZd1ra/9n1ExJURsTIiVm7evHmE3Ts8icEarqKNcAGctrSL3z/vGL65ah3fu9cFUSVJGm0jDVznppROozZd+P6IeGXjnam2T8yo7BWTUvpsSmlFSmnF3LlzR+MpX1BkASsVdEqx7oO/cSynLp3FR759H2uf3dXs7kiSNKmMKHCllNZnl5uAa6jVYD2dTRWSXW7KDl8PLGl4+OKsbX/t48LgCFeTO9IkreUS//DWU4mAD3z1bnr6XSpCkqTRcsDAFRGdETG9fh24ELgfuA6on2l4BXBtdv064J3Z2YpnAduyqccbgQsjoisrlr8wa2u6xrMUJ/Pm1QeyuGsqf/2mk7lv/Tb+x/UuFSFJ0mhpGcEx84Frsqm3FuCrKaUbIuJO4BsR8R5gLfDm7PjrgUuA1cBu4N0AKaUtEfGXwJ3ZcR9LKW0ZtXdymKrVWuCKgk4p1l304iN49znL+Py/P8FpR3Zx6ckLm90lSZImvAMGrpTSGuDkYdqfBV41THsC3r+f57oKuOrgu5m/iiNcAz7y6hO4f/02PvStX3LUnE5esmhms7skSdKEVrBFEIaXqO2jCMWt4WrU1lLiH9/2MrqmtvF/fWkVz+zsaXaXJEma0AofuOoziPUpxaKepTjU3OntfPYdK3hmZw+//5W76KtUm90lSZImrMIHrjqL5p/vpYtn8j/feBJ3PL6Fv7j2AVIalZU/JEkqnJEUzU9+CSqOcA3rslMW8cjGHfzjLb9i0awOPnDBsc3ukiRJE07hA9fAlGK9hssRruf5k4uOY+O2vfzNDx9l/owO3rRiyYEfJEmSBhQ+cEFtifxqwRc+fSERwSfeeBKbd/bw4e/cx5zp7Zx/3Lxmd0uSpAmj8DVcQS1hDdRwOaU4rNZyic+8/WUcf8R0fv/Ld7Fq7dZmd0mSpAmj8IGrruLCpwc0rb2Fz7/7dI6Y2cG7rrqDXz71XLO7JEnShGDgAlJK1E/A8yzFFzZvegdffd+ZdHW28Y5/uZ37129rdpckSRr3Ch+46gNag2cpNrEzE8SCmVP46vvOZHpHK2//l9t5aMP2ZndJkqRxrfCBq66+tY9nKY7M4q6pfO19ZzGltczv/PNtTi9KkvQCDFzUzlJMyXW4DtbS2VP5+pVnM72jld/559v4xa+ebXaXJEkalwofuOrxqr5zjWcpHpyls6fyzd87m0VdU7ji83dw04NPN7tLkiSNO4UPXHUD63D5iRy0+TM6+PqVZ3PCghn83pdX8fU7n2x2lyRJGleMF0BKbl59uLo62/jKe8/k5UfP5r9++z7+6gcPD3ymkiQVXeEDV33drarLQhy2ae0tfP5dp/O2M5fyTz/9FR/42l3s7as0u1uSJDVd4QNXXcWtfUZFS7nE//f6l/DnrzmBH9y/kbf8n1+w/rk9ze6WJElNZeBi6F6KJq7DFRG89xVH8dl3rGDN5l289lO38vPHnml2tyRJaprCB656vLKGa/T95onzufYD5zBvegfvvOp2Pv2T1dZ1SZIKqfCBq84arnwcNXca17z/5bzu5IX89Y2P8L4vruTZnT3N7pYkSWPKwEVt0dPBzaub3JlJaGpbC598yyl87LIXc+tjz3Dx39/KLY9sana3JEkaMwauLGDVa7gc4cpHRPDOs5dx3R+cQ/fUNt71+Tv56LX3exajJKkQDFwZi+bHxvFHzODaD5zD756znC/8Yi2v+dStrFq7pdndkiQpVwYuamcpViyaHzMdrWX+4nUn8qX3nMGe3gpv/Kdf8BfX3s+OvX3N7pokSbkofOCqx6tk0fyYe8Wxc/nhH/8nrjh7GV+6bS0X/t3P+JF7MUqSJqHCBy4AUuMIV5P7UjDT2lv4b5e+mG//55czvaOF935xJb/7r3eyZvPOZndNkqRRU/jANbi1j1OKzXTa0i6+9wev4M8uOYE7Ht/CRZ/8Gf/9+ofY7jSjJGkSKHzgqhsIXA5xNU1bS4n3vfIofvJfzuMNpy7in29dwwV/cwtfvf1J+irVZndPkqRDZuACEmlw4VNHuJpu7vR2/ucbT+ba95/Dstmd/Ok19/Ebf/tTrr1nvSvVS5ImpMIHroGtfZILn443Jy2exTd/72yuetcKpra18MGr7+GST93KDx/YSEoGL0nSxFH4wFVXHzixhmt8iQguOH4+3/+Dc/mHt55KT3+VK7+0ilf//a1ce896+p1qlCRNAAYuaktCpORZiuNZqRS87uSF3PRHr+Rv3nQy/dXEB6++hwv+10/58m1rXbFekjSuFT5w1Qe0qi58OiG0lEu88WWL+eH//Ur+zzteRldnG3/+3fs59xM/4ZM/epRNO/Y2u4uSJD1PS7M7MF44pTixlErBRS8+ggtPnM8v1jzL//npGj75o8f49E9W8+qXLOCKlx/JaUu7Bpb9kCSpmQxc1KYUB4rmCz/mN7FEBC8/eg4vP3oOjz+ziy/9Yi3fXPkU1/3y17xk0QwuP30przt5ITOntDa7q5KkAit8vIjsPMXkCNeEt3xOJ3/xuhO57U9fxcff8BL6K4k//+79nPHxH/GHX7ubWx/bPLCjgCRJY8kRrkzVovlJo7O9hbedeSS/c8ZS7l+/nW+ueorv3r2e6375axbO7OANpy3idScv5Lj5051ylCSNCQMX+y586gjX5BERvHTxTF66eCZ/eskJ3PTg03xz1To+c8uv+PRPfsUx86bxmpcu4HUnL+CYedOb3V1J0iRW+MA1cJaiC59Oah2tZV538kJed/JCNu/o4Yb7N/C9ezfwqZsf4+9//BjHHzGdS166gN84YT4nLHDkS5I0ugofuOqSm1cXxtzp7bzj7GW84+xlbNq+l+vv28D379vA3970KH9706MsnNnBBSfM41UnzOfso2bT0VpudpclSROcgYv6WYq16wauYpk3o4N3nbOcd52znE079nLLw5v50UNP8+1V6/nybU8ypbXMucfO4bzj5nLuMXNY2j3V0S9J0kEzcGUsmte86R28+fQlvPn0Jeztq3Dbmmf58UOb+PFDT3PTg08DsLhrCuceM4eXHzOHlx89mznT2pvca0nSRGDgytRHuBy9ENRqvs47bh7nHTePj132YtY8s4t/X/0MP3/sGb5/3wauvvMpAE5YMIOzj5rNimVdrDiyi3kzOprcc0nSeGTgAhK1Gi5HtzSciODoudM4eu403nn2MvorVe7/9faBAPaV29dy1b8/DsDS7qmsOLKLFcu6WbGsi2PmTqPk/7AkqfAKH7jqI1rVlKzf0oi0lEucsmQWpyyZxfvPP4be/ioP/HobK5/Yysq1W/jpo5v5zt3rAZg5pZWTFs/kpMUzeemiWZy0eCYLZnY4kipJBVP4wFVXTRbM69C0tZQ4dWkXpy7t4n0cRUqJJ57dzZ1PbGHVE1u5d/02/umnawZWuZ8zrT0LYLUgduLCGRwxwxAmSZOZgYvBvRT9751GQ0SwfE4ny+d08uYVSwDY21fhwQ3buW/dNu5dt4371j/HLY9sGqgdnDmlleOOmM4JR0znuCNmcPyC6Rw3fzqd7f5EJWkyKPy/5vWMlZKLnio/Ha1lTlvaxWlLuwbadvX08+CG7Ty0YTsPb9zBwxu28+271rOzZ+3AMUu7p3LcEdN50fxpHDVnGkfPm8ZRczuZ0eFm3JI0kRQ+cNUkqlVruDS2OttbOH1ZN6cv6x5oSymxbuseHt64g0c2buehjTt4ZOMOfvLwJvobNt6eM62do+d2ctTcaRw9t5Oj59aC2MJZU2gtF35PekkadwofuOoZK2ENl5ovIljSPZUl3VP5zRPnD7T3Vao8uWU3azbvYs3mnfxq807WbN7FDfdvYOvuvoHjyqVg4awOlnZPzf46G65PZeZUR8YkqRkKH7jqrOHSeNZaLg0sTQHz97lvy65e1mzeyZpndvHks7t5ckvt74cPPM2zu3r3OXZGRwtLZ09lSddUFsycwsJZHQOXC2dNYe60dpexkKQcGLio1W8lz1LUBNXd2UZ3ZzcrGqYm63b29PNUFsDql09u2c2jT+/gp49uZndvZZ/jW0rB/BkdLJo1hQUNYWzBzCnMm97OvBntzJnW7rSlJB2kwgeuesaquvCpJqFp7S2csGAGJyyY8bz7Ukps39PP+uf2sGHbHn69bS+/fm4PG56rXb/rya1s3LaBvkra53ER0D21jbnT25k3o6MWxKa3125P72DejPasrYMpbW78LUlg4Brgwqcqmohg5tRWZk5t5cSFzw9kANVq4pmdPWzYtpdNO3rYtGMvm7b3sGlHD5t39LB5x14ee3oHm3f07FPUXzeltUx3Zxuzp7VlI3FtzO5so7uzPbtso3ta28D1ae0trkcmaVIycFErmK8m91GUhiqVojaKdYA9IqvVxNbdvWze2TMQyDbt2MuWnb1s2dXLs7t6eXZnL489vZNnd/Wwt6867PO0lUsDwayrs5WZU1qZOaWNmVNamTW1dnvWlKy9fntqG51tZX+/ksa1wgeuyFbici9F6dCVSsHsae3MntbO8Ucc+Pjdvf08m4WxeiDbsqundpm1P7enj43bdrBtTz/b9vQ+b2qzUUspsnDWEMSmtDJjSivTO1qY1l67rP/tc7u9lWkdLZT9B0BSjgofuOqqVYvmpbEyta2Fqd0tLOmeOqLjU0rs6avw3O4+tu3pG7jctqd3n9vP7elj+54+nt3Zy5rNu9i2p4+dPf0D2yq9cJ/KWRhrYXpHa0M4q92e1t5CZ3uZqW0Nl20tTGkr09leprOthaltZTrbW2hvKTniJmkfBi5q/5hbNC+NXxFRC2ltLSycNeWgHptSYm9flR17+9jR08+Ovf3s3Ns/7O2d2e1aex8bt+2t3d9T+xupUtAQxrIg1tbC1IZgNrWtzNT2FjrbynS0lpnSVmZKa3Y9u+xoLe3TXr+vtRwGOmmCKXzgGjxL0RouaTKKiFpoaSsz7zCep1qtjbLt6u1nd0922VthV0/tsvbXz66eIZe9FXb39LOrt58tu3pZt3VPdrv22OFONjiQUtROSJjSVqa9pTGslfYJZgNt2f3tLWXaWkq0Z3+162XaWwfb2lvK+943cL1Ei8uBSIes8IGrLqVEyX9LJO1HqRR0trfUNhSfPnrP29NfYW9flb19Ffb0Vtjbn13W2/oqDZcNxw1ty47b2dPP5h099PRX93m+nv7hT1Q4GOVS0FYuDQS04ULZvqGuFubayrX7W8tBa7lEa7nW1loOWlsabw+2Nd5ua7ydPc/g/SVH/DQhGLion6XoshCSxl4tsJSZOSXfbZeq1URvpUpPf5We/go9fdXa7b7a7d7++n1DbvdVGo57/rG99efrrx3z3J6+2mOGPF9/JdFXqR7SiN5INIa5WoAbDHMDtxtCW0spaCnV2lrKQbkUtJZq11tKQUu54XqpFupayoOPG7ieBb7yAY/LXis7rqUc2fPXrreWSrU+GB4nrcIHrvr/rKuuNC9pEiuVgo5SbboRmrenZrWa6KtW6ask+vqr9FVqwa8vC2S9/dnt/oa2Su24vkqVvv607+1Kord/yO2Bx9du9+xzf5XdeypUqtWBEFipJvoqif5qw/UsHPZX04hOuhhN5XpYywJbuRQDbaWoBbVyxEB741/jMaWo3d73mNLgMaWgVBrumDi4YwZeq0S5BOWGy/31J6L2PstRe/76+ymVglKwT3spe0wpav+dbnzcRFL4wFXnXoqSlL9SKWgvlWlvAdqb3ZuRqVYTlZRqAa1apZJd9ldSFtCycJaFtnpgq1QTfdWG8Jbd33hc4+MHrldSdvxge381Ua1fpsbbtdepNN6XhdD6Y5/3lx1Tv954X3+1SrVK7XJsc+YhqYev5wW4LOiVS7WQVorgqLmdfOk9ZzatrwYu3EtRkrR/pVJQImgtwxSKs11VSvuGsn1CX8Po39CwVw+Ew4W4SjVRTWSXaZ/LSjWREgOv19heTQ2Py/o0cJmyUDykvVLd9z3Mm/7CCzjnzcCVhSyXhZAkaVBkU4EGhdHheXkZi+YlSVJeDFy4l6IkScpX4QNXPWK5l6IkScpL4QMX1Lf2sWhekiTlo/CBa3BrH5eFkCRJ+Sh84KqzhkuSJOXFwJWxhkuSJOWl8IFrsGjeGi5JkpSPEQeuiChHxN0R8b3s9gURcVdE3B8RX4iIlqw9IuJTEbE6Iu6NiNManuOKiHgs+7ti9N/OoXPhU0mSlJeDGeH6IPAQQESUgC8Al6eUXgKsBeoB6tXAsdnflcBnssd0Ax8FzgTOAD4aEV2j8B4OW0r1onkTlyRJGn0jClwRsRh4DfC5rGk20JtSejS7fRPw29n1y4AvpprbgFkRsQC4CLgppbQlpbQ1e8zFo/Q+DlkMbO2DI1ySJCkXIx3h+iTwIaCa3X4GaImIFdntNwJLsuuLgKcaHrsua9tf+z4i4sqIWBkRKzdv3jzC7h2+5NY+kiQpJwcMXBHxWmBTSmlVvS2llIDLgb+LiDuAHUBlNDqUUvpsSmlFSmnF3LlzR+MpD/yauPCpJEnKz0g2AT8HuDQiLgE6gBkR8eWU0tuBVwBExIXAi7Lj1zM42gWwOGtbD5w3pP2Ww+n8aKhHLBc+lSRJeTngCFdK6SMppcUppWXURrVuTim9PSLmAUREO/BfgX/KHnId8M7sbMWzgG0ppQ3AjcCFEdGVFctfmLWNC45wSZKkvIxkhGt//iSbbiwBn0kp3Zy1Xw9cAqwGdgPvBkgpbYmIvwTuzI77WEppy2G8/qhJyYVPJUlSfg4qcKWUbiGbBkwp/QnwJ8Mck4D37+fxVwFXHWwn89S4l6IjXJIkKQ+FX2m+rlp1L0VJkpQPAxeDC586pShJkvJQ+MAV2XmK7qUoSZLyUvjAVVdNiZKfhiRJyoERg/rCp+6lKEmS8mHgyjKWU4qSJCkvBq6MRfOSJCkvBi7qZyk6wiVJkvJR+MDlXoqSJClvhQ9cAInaKFdg4pIkSaOv8IFr3619mtsXSZI0ORU+cNV5lqIkScqLgQsgufCpJEnKT+EjRr1uq5pqtyRJkkZb4QNXXUqJsp+GJEnKgRGDhq19HOGSJEk5KHzgqtfJp4brkiRJo6nwgavOsxQlSVJeDFzUt/ZJze6GJEmapAofuAYGtRzhkiRJOSl84KpzL0VJkpQXAxfZXorg1j6SJCkXhQ9cgwufJsIhLkmSlIPCB666lFxnXpIk5cPARW2V+ZRwhEuSJOWi8IFrcOFTi+YlSVI+Ch+46moLnza7F5IkaTIycFE7Q9G9FCVJUl4MXBmXhZAkSXkxcFGbTkzuXi1JknJS+MAVEdR3UXSES5Ik5aHwgQtqy0IA1nBJkqRcGLjIphNxRlGSJOWj8IErqJ2hCE4pSpKkfBQ+cAFUB0a4TFySJGn0GbhoqOEyb0mSpBwUPnBFDE4pWjQvSZLyUPjABYNF89ZwSZKkPBi4aBjhMnBJkqQcFD5wBY0jXCYuSZI0+gofuGBwhEuSJCkPBi4Y2NrHZSEkSVIeCh+4IsKFTyVJUq4KH7gAqtXapXlLkiTlwcDF4MKnJYe4JElSDgofuGp7KQ5elyRJGm2FD1wAifo6XEYuSZI0+gxcNG5e3dx+SJKkyanwgSuiYfNqJxUlSVIOCh+4YHCEy5p5SZKUBwMXDSNcBi5JkpQDAxfRUMNl4pIkSaPPwMXgXorGLUmSlIfCB65a0XzteskRLkmSlIPCBy5oGOEyb0mSpBwYuKBh82oTlyRJGn2FD1z7bO1j3pIkSTkofOACyHb2kSRJyoWBC6cUJUlSvgofuCIsmpckSfkqfOCCwRlFR7gkSVIeDFwMrsNl3JIkSXkofOCKhpjl1j6SJCkPhQ9cjcxbkiQpDwauBtZwSZKkPBQ+cDVmLOOWJEnKQ+EDVyMHuCRJUh4MXA2cUpQkSXkofODaJ2OZtyRJUg4KH7gaOcIlSZLyYOBqYNySJEl5KHzgalz41BEuSZKUh8IHrkbmLUmSlAcDl+twSZKknI04cEVEOSLujojvZbdfFRF3RcQ9EfHziDgma2+PiK9HxOqIuD0iljU8x0ey9kci4qJRfzeHyb0UJUlSHg5mhOuDwEMNtz8DvC2ldArwVeDPs/b3AFtTSscAfwd8AiAiTgQuB14MXAz8Y0SUD6v3o8y8JUmS8jCiwBURi4HXAJ9raE7AjOz6TODX2fXLgC9k178FvCpqQ0eXAVenlHpSSo8Dq4EzDq/7h68xY1k0L0mS8tAywuM+CXwImN7Q9l7g+ojYA2wHzsraFwFPAaSU+iNiGzA7a7+t4fHrsrZ9RMSVwJUAS5cuHen7GBXmLUmSlIcDjnBFxGuBTSmlVUPu+iPgkpTSYuDzwN+ORodSSp9NKa1IKa2YO3fuaDzliJUMXJIkKQcjGeE6B7g0Ii4BOoAZEfF94PiU0u3ZMV8HbsiurweWAOsiooXadOOzDe11i7O2pgr39pEkSTk74AhXSukjKaXFKaVl1Ireb6ZWjzUzIl6UHfabDBbUXwdckV1/I3BzSill7ZdnZzEuB44F7hi1dzIKHOGSJEl5GGkN1z6y2qz3Ad+OiCqwFfjd7O5/Ab4UEauBLdRCGimlByLiG8CDQD/w/pRS5XDfwGhyWQhJkpSHgwpcKaVbgFuy69cA1wxzzF7gTft5/MeBjx9sJ/PkhKIkScqbK803cFkISZKUBwNXA/OWJEnKQ+EDV2PIMnBJkqQ8FD5wNQqruCRJUg4MXA1KfhqSJCkHhY8Y+56l6AiXJEkafYUPXI1c+FSSJOXBwNXAonlJkpSHwgcu91KUJEl5K3zgauSUoiRJyoOBq4F7KUqSpDwUPnA1RixHuCRJUh4KH7gauSyEJEnKg4HLrX0kSVLODFwNDFySJCkPBq4GFs1LkqQ8FD5wNdZtWTQvSZLyUPjA1ciieUmSlAcDVwNHuCRJUh4KH7jc2UeSJOWt8IGrUcmieUmSlAMDVwPjliRJykPhA9e+W/sYuSRJ0ugrfOBqZN6SJEl5MHA1cFkISZKUh8IHrsZRrSj8pyFJkvJgxGjg+JYkScqDgauBRfOSJCkPhQ9cjXVb5i1JkpSHwgeuRo5wSZKkPBi4JEmSclb4wNU4qOUIlyRJykPhA1cj85YkScpD4QPXPutwNa8bkiRpEit84GrklKIkScqDgauBeUuSJOXBwLXPOlwmLkmSNPoMXBmzliRJyouBK2P9liRJykvhA1c9Zxm3JElSXgofuOoc4JIkSXkxcGUsmJckSXkpfOCKIZeSJEmjrfCBq86ieUmSlBcDV8a8JUmS8lL4wFUPWo5wSZKkvBQ+cNUZtyRJUl4MXBkHuCRJUl4KH7giG9tyWQhJkpSXwgeuOvOWJEnKi4ErY9G8JEnKS+EDl3spSpKkvBU+cNVZwyVJkvJi4MqYtyRJUl4KH7jqOatk4JIkSTkpfOCqC6u4JElSTgofuOq1W45wSZKkvBQ+cNVZNC9JkvJi4JIkScqZgStT8pOQJEk5MWZkLJqXJEl5MXBlLJqXJEl5KXzgGtjax6J5SZKUk8IHrjrzliRJyouBK2PekiRJeSl84KoXyzulKEmS8lL4wFVn0bwkScqLgSvjshCSJCkvhQ9cg2cpNrcfkiRp8ip84KqzhkuSJOXFwJWxhkuSJOWl8IGrnrMc4JIkSXkpfOCqK5m4JElSTkYcuCKiHBF3R8T3stu3RsQ92d+vI+K7WXtExKciYnVE3BsRpzU8xxUR8Vj2d8Wov5vDYNySJEl5aTmIYz8IPATMAEgpvaJ+R0R8G7g2u/lq4Njs70zgM8CZEdENfBRYASRgVURcl1Laerhv4nCEc4qSJClnIxrhiojFwGuAzw1z3wzgAuC7WdNlwBdTzW3ArIhYAFwE3JRS2pKFrJuAiw//LYwOi+YlSVJeRjql+EngQ0B1mPteD/w4pbQ9u70IeKrh/nVZ2/7a9xERV0bEyohYuXnz5hF279DVl4Mwb0mSpLwcMHBFxGuBTSmlVfs55K3A10arQymlz6aUVqSUVsydO3e0nvaALJqXJEl5GckI1znApRHxBHA1cEFEfBkgIuYAZwDfbzh+PbCk4fbirG1/7eOCeUuSJOXlgIErpfSRlNLilNIy4HLg5pTS27O73wh8L6W0t+Eh1wHvzM5WPAvYllLaANwIXBgRXRHRBVyYtTXVYM28iUuSJOXjYM5SHM7lwF8NabseuARYDewG3g2QUtoSEX8J3Jkd97GU0pbDfP1RY9ySJEl5OajAlVK6Bbil4fZ5wxyTgPfv5/FXAVcdzGuOFWu4JElSXlxpPstZ5i1JkpQXA1fGwCVJkvJi4Mo4pShJkvJS+MAVlstLkqScFT5w1TnCJUmS8mLgypi3JElSXgofuOpByxEuSZKUl8IHrjrjliRJyouBK+PWPpIkKS+FD1yDeyk2tRuSJGkSK3zgqjNvSZKkvBi4MhbNS5KkvBQ+cIV7KUqSpJwVPnDVOcIlSZLyYuCqM29JkqScFD5w1fdSdIRLkiTlpfCBq864JUmS8lL4wGXRvCRJylvhA1edU4qSJCkvBq6McUuSJOWl8IFrcGsfI5ckScpH4QNXnXlLkiTlxcCVKRm4JElSTgxc2dBWWMUlSZJyYuDKlPwkJElSTowZAxzhkiRJ+Sh84Bo8S7Gp3ZAkSZNY4QNXnUXzkiQpLwaujEXzkiQpL4UPXO6lKEmS8lb4wFXnXoqSJCkvBq6MgUuSJOWl8IGrXrtl0bwkScpL4QNXXdnEJUmScmLgyoRTipIkKSeFD1z1nOUAlyRJykvhA1dKtUunFCVJUl4KH7iqWeJySlGSJOWl8IErZYGrbOCSJEk5KXzgqmZTis4oSpKkvBQ+cFWyEa6SiUuSJOWk8IGrXsPlSvOSJCkvhQ9cySlFSZKUs8IHrkrVES5JkpQvA1fVGi5JkpSvwgeuNFDD1eSOSJKkSavwgWtwWQgTlyRJykfhA5fLQkiSpLwVPnA5pShJkvJW+MBVrdYunVKUJEl5KXzgqriXoiRJylnhA1d9pXnzliRJykvhA1fyLEVJkpSzwgeu+sKnZavmJUlSTgofuKouCyFJknJW+MDl5tWSJClvhQ9cbl4tSZLyVvjANTClaOCSJEk5MXA5pShJknJW+MCVHOGSJEk5K3zgGty8uskdkSRJk1bhY4ZF85IkKW+FD1yuNC9JkvJW+MDlWYqSJClvhQ9cA1OKhf8kJElSXgofM5xSlCRJeSt84HJKUZIk5a3wgau+LES58J+EJEnKS+FjRtUpRUmSlLPCBy5XmpckSXkrfOBy4VNJkpS3wgeugSnFwn8SkiQpL4WPGU4pSpKkvI04cEVEOSLujojvZbcjIj4eEY9GxEMR8YcN7Z+KiNURcW9EnNbwHFdExGPZ3xWj/3YOnlOKkiQpby0HcewHgYeAGdntdwFLgONTStWImJe1vxo4Nvs7E/gMcGZEdAMfBVYACVgVEdellLYe9rs4DFWXhZAkSTkbUcyIiMXAa4DPNTT/Z+BjKaUqQEppU9Z+GfDFVHMbMCsiFgAXATellLZkIesm4OJReh+HrF7DFY5wSZKknIx0XOeTwIeAakPb0cBbImJlRPwgIo7N2hcBTzUcty5r21/7PiLiyuw5V27evHmE3Tt0AyNcBi5JkpSTAwauiHgtsCmltGrIXe3A3pTSCuCfgatGo0Mppc+mlFaklFbMnTt3NJ7yBf3Nm07mrKO6WdQ1JffXkiRJxTSSEa5zgEsj4gngauCCiPgytRGq72THXAOclF1fT622q25x1ra/9qY6fVk3V195Nq0WcUmSpJwcMGWklD6SUlqcUloGXA7cnFJ6O/Bd4PzssP8EPJpdvw54Z3a24lnAtpTSBuBG4MKI6IqILuDCrE2SJGlSO5izFIf6K+ArEfFHwE7gvVn79cAlwGpgN/BugJTSloj4S+DO7LiPpZS2HMbrS5IkTQhRX/hzPFqxYkVauXJls7shSZJ0QBGxKqttfx4LlyRJknJm4JIkScqZgUuSJClnBi5JkqScGbgkSZJyZuCSJEnKmYFLkiQpZwYuSZKknBm4JEmScmbgkiRJypmBS5IkKWcGLkmSpJwZuCRJknJm4JIkScqZgUuSJClnBi5JkqScGbgkSZJyZuCSJEnKmYFLkiQpZwYuSZKknEVKqdl92K+I2AysHYOXmgM8Mwavo5HzOxmf/F7GH7+T8cnvZXzK+3s5MqU0d7g7xnXgGisRsTKltKLZ/dAgv5Pxye9l/PE7GZ/8XsanZn4vTilKkiTlzMAlSZKUMwNXzWeb3QE9j9/J+OT3Mv74nYxPfi/jU9O+F2u4JEmScuYIlyRJUs4MXJIkSTkrdOCKiIsj4pGIWB0RH252f4okIpZExE8i4sGIeCAiPpi1d0fETRHxWHbZlbVHRHwq+67ujYjTmvsOJq+IKEfE3RHxvez28oi4Pfvsvx4RbVl7e3Z7dXb/sqZ2fBKLiFkR8a2IeDgiHoqIs/2tNFdE/FH2b9f9EfG1iOjwtzL2IuKqiNgUEfc3tB30byMirsiOfywirsijr4UNXBFRBj4NvBo4EXhrRJzY3F4VSj/w/6SUTgTOAt6fff4fBn6cUjoW+HF2G2rf07HZ35XAZ8a+y4XxQeChhtufAP4upXQMsBV4T9b+HmBr1v532XHKx98DN6SUjgdOpvb9+FtpkohYBPwhsCKl9BKgDFyOv5Vm+Ffg4iFtB/XbiIhu4KPAmcAZwEfrIW00FTZwUftQV6eU1qSUeoGrgcua3KfCSCltSCndlV3fQe0/IIuofQdfyA77AvD67PplwBdTzW3ArIhYMLa9nvwiYjHwGuBz2e0ALgC+lR0y9Dupf1ffAl6VHa9RFBEzgVcC/wKQUupNKT2Hv5VmawGmREQLMBXYgL+VMZdS+hmwZUjzwf42LgJuSiltSSltBW7i+SHusBU5cC0Cnmq4vS5r0xjLhtdPBW4H5qeUNmR3bQTmZ9f9vsbGJ4EPAdXs9mzguZRSf3a78XMf+E6y+7dlx2t0LQc2A5/Ppno/FxGd+FtpmpTSeuBvgCepBa1twCr8rYwXB/vbGJPfTJEDl8aBiJgGfBv4v1NK2xvvS7U1S1y3ZIxExGuBTSmlVc3ui/bRApwGfCaldCqwi8EpEsDfyljLppsuoxaGFwKd5DAiosM3nn4bRQ5c64ElDbcXZ20aIxHRSi1sfSWl9J2s+en69Ed2uSlr9/vK3znApRHxBLUp9guo1Q7NyqZNYN/PfeA7ye6fCTw7lh0uiHXAupTS7dntb1ELYP5Wmuc3gMdTSptTSn3Ad6j9fvytjA8H+9sYk99MkQPXncCx2VklbdQKHq9rcp8KI6tf+BfgoZTS3zbcdR1QP0PkCuDahvZ3ZmeZnAVsaxgy1ihIKX0kpbQ4pbSM2u/h5pTS24CfAG/MDhv6ndS/qzdmx4+L/yc5maSUNgJPRcRxWdOrgAfxt9JMTwJnRcTU7N+y+nfib2V8ONjfxo3AhRHRlY1eXpi1japCrzQfEZdQq1kpA1ellD7e3B4VR0ScC9wK3MdgvdCfUqvj+gawFFgLvDmltCX7R+1/Uxu23w28O6W0csw7XhARcR7wX1JKr42Io6iNeHUDdwNvTyn1REQH8CVq9XdbgMtTSmua1OVJLSJOoXYiQxuwBng3tf/D7G+lSSLi/wXeQu2M67uB91Kr+/G3MoYi4mvAecAc4GlqZxt+l4P8bUTE71L7bxDAx1NKnx/1vhY5cEmSJI2FIk8pSpIkjQkDlyRJUs4MXJIkSTkzcEmSJOXMwCVJkpQzA5ckSVLODFySJEk5+/8Bb4umjMWAIlwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.plot(model.training_losses)\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87d64d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvict\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9972808252056388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regr = MLPRegressor(random_state=1, max_iter=500).fit(X1_train, y1_train)\n",
    "regr.predict(X1_test)\n",
    "regr.score(X1_test, y1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4d410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPregressor\n",
      "Train MSE : 54.97323981433775\n",
      "Test MSE : 56.233644868514\n",
      "\n",
      "Our model:\n",
      "Train MSE : 20507.248407268227\n",
      "Test MSE : 20688.127718007814\n"
     ]
    }
   ],
   "source": [
    "# mlpregressor model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"MLPregressor\")\n",
    "test_mse = mean_squared_error(y1_test, regr.predict(X1_test))\n",
    "train_mse = mean_squared_error(y1_train, regr.predict(X1_train))\n",
    "print(f'Train MSE : {train_mse}')\n",
    "print(f'Test MSE : {test_mse}')\n",
    "\n",
    "# our model \n",
    "test_mse = mean_squared_error(y1_test, model.predict(X1_test))\n",
    "train_mse = mean_squared_error(y1_train, model.predict(X1_train))\n",
    "print(\"\\nOur model:\")\n",
    "print(f'Train MSE : {train_mse}')\n",
    "print(f'Test MSE : {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt2 = pd.read_table('Part 2.tsv', comment='#')\n",
    "\n",
    "X2 = pt2.iloc[:, :4].values\n",
    "y2 = pt2[\"target\"].values\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3 implement the activation and cost functions\n",
    "def sigmoid(Z):\n",
    "    return 1.0 / (1.0 + np.exp(-Z))\n",
    "\n",
    "def sigmoid_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "def cost_function(y2, y2_hat):\n",
    "    return -np.sum(y2*(np.log(y2_hat)) + (1 - y2)*np.log(1 - y2_hat)) / y2.shape[0]\n",
    "\n",
    "def cost_gradient(y2, y2_hat):\n",
    "    return -np.divide(y2, y2_hat) + np.divide(1.0 - y2, 1.0 - y2_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "def print_dim(name, var):\n",
    "    print(f\"{name} = {var.shape}\")\n",
    "\n",
    "class MultiLayerPerceptronClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A fully connected 5-layer perceptron for binary regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    size_hidden : int\n",
    "        The size of the hidden layer\n",
    "    epochs : int\n",
    "        The number of epochs to train the model\n",
    "    leargning_rate : float\n",
    "        The learning rate for the gradient descent\n",
    "    batch_size : int, default 50\n",
    "        The number of datapoints in each mini-batch\n",
    "    random_state : random_state, default None\n",
    "        a numpy random state for reproducibility. If None (default)\n",
    "        The default numpy random generator with seed 0 will be used\n",
    "\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This implementation initializes the weights using a random Gaussian\n",
    "    distribution with mean 0 and standard deviation 0.001\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 size_hidden, \n",
    "                 epochs, \n",
    "                 learning_rate, \n",
    "                 batch_size, \n",
    "                 random_state=None):\n",
    "        self.size_hidden = size_hidden\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        if random_state is None:\n",
    "            self.rng = np.random.default_rng(0)\n",
    "        else:\n",
    "            self.rng = random_state\n",
    "        # the dimensionality of _W0 will be set in the fit function\n",
    "        self._W1 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W2 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W3 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W4 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, self.size_hidden))\n",
    "\n",
    "        #weight\n",
    "        self._W5 = self.rng.normal(scale=0.001, size=(self.size_hidden + 1, 1))\n",
    "        self.training_losses = np.zeros(self.epochs)\n",
    "        \n",
    "    def _forward(self, X1):\n",
    "        # 1st layer\n",
    "        self.O1 = X1 @ self._W0\n",
    "        self.A1 = sigmoid(self.O1)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A1.shape\n",
    "        self.A1 = np.c_[np.ones((n, 1)), self.A1]\n",
    "\n",
    "        # 2nd layer \n",
    "        self.Z2 = self.A1 @ self._W1\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A2.shape\n",
    "        self.A2 = np.c_[np.ones((n, 1)), self.A2]\n",
    "\n",
    "        # 3rd layer \n",
    "        self.Z3 = self.A2 @ self._W2\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A3.shape\n",
    "        self.A3 = np.c_[np.ones((n, 1)), self.A3]\n",
    "\n",
    "        # 4th layer \n",
    "        self.Z4 = self.A3 @ self._W3\n",
    "        self.A4 = sigmoid(self.Z4)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A4.shape\n",
    "        self.A4 = np.c_[np.ones((n, 1)), self.A4]\n",
    "\n",
    "        # 5th layer\n",
    "        self.O5 = self.A4 @ self._W4\n",
    "        self.A5 = sigmoid(self.O5)\n",
    "\n",
    "        # add bias\n",
    "        n, _ = self.A5.shape\n",
    "        self.A5 = np.c_[np.ones((n, 1)), self.A5]\n",
    "\n",
    "        # 6th layer or output layer\n",
    "        self.O6 = self.A5 @ self._W5\n",
    "        self.A6 = sigmoid(self.O6)\n",
    "\n",
    "        # return the identity of the output layer instead of the sigmoid\n",
    "        return self.A6\n",
    "        \n",
    "    def _backward(self, X1, y1):\n",
    "\n",
    "        # starting by the last one\n",
    "        dA6 = cost_gradient(y1, self.A6)\n",
    "        dO6 = dA6 * sigmoid_derivative(sigmoid(self.O6))\n",
    "        dW5 = self.A5.T @ dO6\n",
    "\n",
    "        # 5th layer backpropagation\n",
    "        dA5 = dO6 @ self._W5[1:,:].T\n",
    "        dO5 = dA5 * sigmoid_derivative(sigmoid(self.O5))\n",
    "        dW4 = self.A4.T @ dO5\n",
    "\n",
    "        # 4th layer backpropagation\n",
    "        dA4 = dO5 @ self._W4[1:,:].T\n",
    "        dO4 = dA4 * sigmoid_derivative(sigmoid(self.Z4))\n",
    "        dW3 = self.A3.T @ dO4\n",
    "\n",
    "        # 3rd layer backpropagation\n",
    "        dA3 = dO4 @ self._W3[1:,:].T\n",
    "        dO3 = dA3 * sigmoid_derivative(sigmoid(self.Z3))\n",
    "        dW2 = self.A2.T @ dO3\n",
    "\n",
    "        # 2nd layer backpropagation\n",
    "        dA2 = dO3 @ self._W2[1:,:].T\n",
    "        dO2 = dA2 * sigmoid_derivative(sigmoid(self.Z2))\n",
    "        dW1 = self.A1.T @ dO2\n",
    "\n",
    "        # 1st layer backpropagation\n",
    "        dA1 = dO2 @ self._W1[1:,:].T\n",
    "        dO1 = dA1 * sigmoid_derivative(sigmoid(self.O1))\n",
    "        dW0 = X1.T @ dO1\n",
    "\n",
    "        return dW0, dW1, dW2, dW3, dW4, dW5\n",
    "\n",
    "        \n",
    "    def _weight_update(self, dW0, dW1, dW2, dW3, dW4, dW5, curr_batch_size):\n",
    "        self._W0 -= self.learning_rate * dW0\n",
    "        self._W1 -= self.learning_rate * dW1\n",
    "        self._W2 -= self.learning_rate * dW2\n",
    "        self._W3 -= self.learning_rate * dW3\n",
    "        self._W4 -= self.learning_rate * dW4\n",
    "        self._W5 -= self.learning_rate * dW5\n",
    "\n",
    "\n",
    "    def fit(self, X1, y1):\n",
    "        X1, y1 = check_X_y(X1, y1)\n",
    "        n, m = X1.shape\n",
    "        _X1 = np.c_[np.ones((n, 1)), X1]\n",
    "        _y1 = y1[:,np.newaxis]\n",
    "        self._W0 = self.rng.normal(scale=0.001, size=(m+1, self.size_hidden))\n",
    "        \n",
    "        #number of batches\n",
    "        n_batches = (n + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for epoch in track(range(self.epochs), description=\"Training...\"):\n",
    "            for b in range(n_batches):\n",
    "                _X1_batch = _X1[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                _y1_batch = _y1[b * self.batch_size : (b + 1) * self.batch_size]\n",
    "                y_pred = self._forward(_X1_batch)\n",
    "                dW0, dW1, dW2, dW3, dW4, dW5  = self._backward(_X1_batch, _y1_batch)\n",
    "                curr_batch_size = _y1_batch.shape[0]\n",
    "                self._weight_update(dW0, dW1, dW2, dW3, dW4, dW5, curr_batch_size)\n",
    "            y1_pred = self._forward(_X1)\n",
    "            self.training_losses[epoch] = cost_function(_y1, y1_pred)\n",
    "        \n",
    "        self.fitted_ = True\n",
    "    \n",
    "    def predict(self, X1):\n",
    "        return self.predict_proba(X1).argmax(axis=1)\n",
    "    \n",
    "    def predict_proba(self, X1):\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        X1 = check_array(X1)\n",
    "        n, m = X1.shape\n",
    "        _X1 = np.c_[np.ones((n, 1)), X1]\n",
    "        \n",
    "        pred_1 = self._forward(_X1)\n",
    "        pred_0 = 1 - pred_1\n",
    "        return np.c_[pred_0, pred_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt3 = pd.read_csv('Adult.data', comment='#', header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'target'])\n",
    "\n",
    "pt3 ['target'] = pd.to_numeric(pt3['target'], errors='coerce')\n",
    "pt3 = pt3.replace(np.nan, 0, regex=True)\n",
    "\n",
    "X3 = pt3.iloc[:, :14].values\n",
    "y3 = pt3['target'].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def entropy(y3):\n",
    "    hist = np.bincount(y3)\n",
    "    ps = hist / len(y3)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X3, y3):\n",
    "        self.n_feats = X3.shape[1] if not self.n_feats else min(self.n_feats, X3.shape[1])\n",
    "        self.root = self._grow_tree(X3, y3)\n",
    "\n",
    "    def predict(self, X3):\n",
    "        return np.array([self._traverse_tree(x3, self.root) for x3 in X3])\n",
    "\n",
    "    def _grow_tree(self, X3, y3, depth=0):\n",
    "        n_samples, n_features = X3.shape\n",
    "        n_labels = len(np.unique(y3))\n",
    "\n",
    "        # stopping criteria\n",
    "        if (depth >= self.max_depth\n",
    "                or n_labels == 1\n",
    "                or n_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y3)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "        # greedily select the best split according to information gain\n",
    "        best_feat, best_thresh = self._best_criteria(X3, y3, feat_idxs)\n",
    "        \n",
    "        # grow the children that result from the split\n",
    "        left_idxs, right_idxs = self._split(X3[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X3[left_idxs, :], y3[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X3[right_idxs, :], y3[right_idxs], depth+1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_criteria(self, X3, y3, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X3_column = X3[:, feat_idx]\n",
    "            thresholds = np.unique(X3_column)\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y3, X3_column, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _information_gain(self, y3, X3_column, split_thresh):\n",
    "        # parent loss\n",
    "        parent_entropy = entropy(y3)\n",
    "\n",
    "        # generate split\n",
    "        left_idxs, right_idxs = self._split(X3_column, split_thresh)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the loss for the children\n",
    "        n = len(y3)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = entropy(y3[left_idxs]), entropy(y3[right_idxs])\n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        # information gain is difference in loss before vs. after split\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X3_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X3_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X3_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _traverse_tree(self, x3, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x3[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x3, node.left)\n",
    "        return self._traverse_tree(x3, node.right)\n",
    "\n",
    "    def _most_common_label(self, y3):\n",
    "        counter = Counter(y3)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def bootstrap_sample(X3, y3):\n",
    "    n_samples = X3.shape[0]\n",
    "    idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "    return X3[idxs], y3[idxs]\n",
    "\n",
    "def most_common_label(y3):\n",
    "    counter = Counter(y3)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, num_trees=10, min_samples_split=2,\n",
    "                 max_depth=100, n_feats=None, n_estimators=100, random_state=0):\n",
    "        self.num_trees = num_trees\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X3, y3):\n",
    "        self.trees = []\n",
    "        for _ in range(self.num_trees):\n",
    "            tree = DecisionTree(min_samples_split=self.min_samples_split,\n",
    "                max_depth=self.max_depth, n_feats=self.n_feats)\n",
    "            X3_samp, y3_samp = bootstrap_sample(X3, y3)\n",
    "            tree.fit(X3_samp, y3_samp)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X3):\n",
    "        tree_preds = np.array([tree.predict(X3) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        y3_pred = [most_common_label(tree_pred) for tree_pred in tree_preds]\n",
    "        return np.array(y3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jvict\\Downloads\\A2\\843586.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000027?line=5'>6</a>\u001b[0m num_features \u001b[39m=\u001b[39m X3_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000027?line=7'>8</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForest(min_samples_split\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, num_trees\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_feats\u001b[39m=\u001b[39mnum_features,  n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000027?line=8'>9</a>\u001b[0m rf\u001b[39m.\u001b[39;49mfit(X3_train, y3_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000027?line=9'>10</a>\u001b[0m test_mse \u001b[39m=\u001b[39m mean_squared_error(y3_test, rf\u001b[39m.\u001b[39mpredict(X3_test))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000027?line=10'>11</a>\u001b[0m train_mse \u001b[39m=\u001b[39m mean_squared_error(y3_train, rf\u001b[39m.\u001b[39mpredict(X3_train))\n",
      "\u001b[1;32mc:\\Users\\jvict\\Downloads\\A2\\843586.ipynb Cell 27'\u001b[0m in \u001b[0;36mRandomForest.fit\u001b[1;34m(self, X3, y3)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000026?line=27'>28</a>\u001b[0m tree \u001b[39m=\u001b[39m DecisionTree(min_samples_split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_samples_split,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000026?line=28'>29</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth, n_feats\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_feats)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000026?line=29'>30</a>\u001b[0m X3_samp, y3_samp \u001b[39m=\u001b[39m bootstrap_sample(X3, y3)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000026?line=30'>31</a>\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X3_samp, y3_samp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000026?line=31'>32</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\u001b[39m.\u001b[39mappend(tree)\n",
      "\u001b[1;32mc:\\Users\\jvict\\Downloads\\A2\\843586.ipynb Cell 26'\u001b[0m in \u001b[0;36mDecisionTree.fit\u001b[1;34m(self, X3, y3)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X3, y3):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=32'>33</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_feats \u001b[39m=\u001b[39m X3\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_feats \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_feats, X3\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=33'>34</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow_tree(X3, y3)\n",
      "\u001b[1;32mc:\\Users\\jvict\\Downloads\\A2\\843586.ipynb Cell 26'\u001b[0m in \u001b[0;36mDecisionTree._grow_tree\u001b[1;34m(self, X3, y3, depth)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_grow_tree\u001b[39m(\u001b[39mself\u001b[39m, X3, y3, depth\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=39'>40</a>\u001b[0m     n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=40'>41</a>\u001b[0m     n_labels \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y3))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jvict/Downloads/A2/843586.ipynb#ch0000025?line=42'>43</a>\u001b[0m     \u001b[39m# stopping criteria\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X3, y3 = make_classification(n_samples=400, n_features=15)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3)\n",
    "\n",
    "num_features = X3_train.shape[1] // 3\n",
    "\n",
    "rf = RandomForest(min_samples_split=20, max_depth=6, num_trees=10, n_feats=num_features,  n_estimators=100, random_state=0)\n",
    "rf.fit(X3_train, y3_train)\n",
    "test_mse = mean_squared_error(y3_test, rf.predict(X3_test))\n",
    "train_mse = mean_squared_error(y3_train, rf.predict(X3_train))\n",
    "\n",
    "print(f'Train MSE : {train_mse}')\n",
    "print(f'Test MSE : {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE : 0.49333333333333335\n",
      "Test MSE : 0.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X2, y2 = make_classification(n_samples=400, n_features=15)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X3, y3)\n",
    "\n",
    "num_features = X2_train.shape[1] // 3\n",
    "\n",
    "rf = RandomForest(min_samples_split=20, max_depth=6, num_trees=10, n_feats=num_features,  n_estimators=100, random_state=0)\n",
    "rf.fit(X2_train, y2_train)\n",
    "test_mse = mean_squared_error(y2_test, rf.predict(X2_test))\n",
    "train_mse = mean_squared_error(y2_train, rf.predict(X2_train))\n",
    "\n",
    "print(f'Train MSE : {train_mse}')\n",
    "print(f'Test MSE : {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_random = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, random_state=0)\n",
    "\n",
    "model_random.fit(X2_train, y2_train)\n",
    "\n",
    "pred = model_random.predict(X2_test)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_random1 = RandomForest(min_samples_split=20, max_depth=6, num_trees=10, n_feats=num_features,  n_estimators=100, random_state=1)\n",
    "\n",
    "\n",
    "model_random1.fit(X2_train, y2_train)\n",
    "\n",
    "pred = model_random1.predict(X2_test)\n",
    "\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a3fd4dd5fe32bc568ead0b1afe4820799914cb188ee2602122afe9a2b16b10a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
